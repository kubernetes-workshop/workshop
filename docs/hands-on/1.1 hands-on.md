# Hands-On Kubernetes Basics

prerequisites:

* git
* docker
* kubectl
* docker hub account (2min)

## Download .kube\config

```
# 1) clean up local configuration files before creating a new cluster
del $HOME\.kube\config
del $HOME\.azure\aksServicePrincipal.json

# 2) download .kube\config
mkdir $HOME\.kube\config
Invoke-WebRequest 'https://handelsblatt.blob.core.windows.net/kube/config' -OutFile $HOME\.kube\config

# 3) test connection to cluster
kubectl get nodes
```

## Exercise 1

* deploy using imperative commands
* create service
* port mappings
* port-forward
* set-context: specify namespace

```
# deploy to kubernetes
kubectl run hello --image nginx --labels=app=hello --port 80 --namespace team2
kubectl get pod -n team2
kubectl port-forward pod/hello-xxxxxxxxxx-xxxxx 8000:80
visit http://localhost:8000

# create service with ClusterIP
kubectl expose deployments hello --port 80 --type ClusterIP -n team2
kubectl get services -n team2
kubectl port-forward service/hello 8000:80
visit http://localhost:8000

# set default namespace
kubectl config set-context $(kubectl config current-context) --namespace=team2

# validate it
kubectl config view
kubectl get pod
kubectl get pod -n team1
kubectl get services
kubectl get services -n team1

```

## Exercise 2

* build docker image
* push docker image to registry
* get manifests based on already deployed pods and services
* deploy using manifests (declarative)

```
#
cd podinfo

# build and publish to DockerHub
$version="v1"
$username="your-dockerhub-username"

docker build . --tag $username/podinfo:$version
docker login --username $username --password xxxxxxxx
docker push $username/podinfo:$version

# get current manifests from 'hello' and create deployment.yaml and service.yaml
kubectl get deployment hello -o yaml
kubectl get service hello -o yaml

# replace labels, selectors and images according to the new application:
# name: podinfo
# image: your-dockerhub-username/podinfo:v1 
# etc..

# run in kubernetes
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
kubectl get all -n team2

# check result
kubectl port-forward service/podinfo 8000:80
visit http://localhost:8000

# troubleshoot => ask for help
kubectl describe pod/podinfo-xxxxxxxx-xxxx -n team2
kubectl logs pod/podinfo-xxxxxxxx-xxxx -n team2
```


## Exercise 3

* ingress

```
kubectl apply -f ingress.yaml

# give it a minute to install
visit http://team2.ddnss.de/
visit http://team2.ddnss.de/podinfo

# play around (subdomain, wildcard, regex)
# 1) host: "podinfo.team2.ddnss.de"
# 2) path: /*
# 3) path: /foo/bar/[A-Z0-9]{3}

# troubleshoot
kubectl port-forward service/hello 8001:80
kubectl port-forward service/podinfo 8002:80
visit http://localhost:8001
visit http://localhost:8002
```

## Exercise 4

* HorizontalPodAutoscaller

```
kubectl run fibo --image=fnbk/fibo --requests=cpu=200m --expose --port=80 -n team2
kubectl autoscale deployment fibo --cpu-percent=50 --min=2 --max=10 -n team2
kubectl get all -n team2

# for each command open a new powershell (see scaling in action)
kubectl get hpa --watch
kubectl get pod --watch --selector run=fibo

# loadtest manual
kubectl run -it --rm manual-loadtest --image=fnbk/loadtest /bin/bash
curl http://fibo.team2.svc.cluster.local # check DNS resolution
/app/hey -z 3s -c 64 -m GET http://fibo.team2.svc.cluster.local # make 64 requests in 3 seconds

# cleanup manual loadtest
kubectl get all -l run=manual-loadtest
kubectl delete deployment/manual-loadtest -n team2

# loadtest using a job
kubectl apply -f loadtest.yaml

# inspect, see what happens, see scaling in action
kubectl get all -n team2
kubectl describe job.batch/loadtest -n team2
kubectl logs pod/loadtest-job-xxxxx -n team2

# cleanup loadtest job
kubectl get all -n team2
kubectl delete -f ./loadtest.yaml
```


